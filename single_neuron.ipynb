{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprogagation for two Output Neurons with one Input\n",
    "\n",
    "The input of the two Neurons N_1 and N_2 is x and the bias, b, and the associated weights are called (w1, w2) and (w3, w4), respectively. The output then defines if the input value x is of group A or group B, depending on which value is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the learning parameter, initalise randomly the weights and declare necessary functions: the sigmoid, the loss function as well as their derivations. Here we use the square error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 0.01 # Learning Parameter\n",
    "w = np.random.uniform(-1, 1, (4,)) # Random initialisation of the weights w_1 and w_2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_deri(x):\n",
    "    val = sigmoid(x)\n",
    "    return val / (1 - val)\n",
    "def loss(y_hat, y):\n",
    "    sum_y = np.power((y[0]-y_hat[0]), 2) + np.power((y[1]-y_hat[1]), 2)\n",
    "    return sum_y\n",
    "def loss_deri(y_hat, y):\n",
    "    return 2.0*(y_hat-y)\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these elements, we can calculate a forward pass through the network for the input x and the label y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x, y):\n",
    "    if y==1:\n",
    "        y=np.array([0, 1])\n",
    "    else:\n",
    "        y=np.array([1, 0])\n",
    "    #z_1 = np.sum(w[0]*x, w[1]) # Sum in Neuron\n",
    "    z_1 = w[0]*x + w[1]\n",
    "    z_2 = w[2]*x + w[3]\n",
    "    y_hat = np.array([sigmoid(z_1), sigmoid(z_2)]) # Output of activation function of Neuron\n",
    "    loss_val = loss(y_hat, y) # Final value of the loss function\n",
    "    return z_1, y_hat, loss_val, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define the backward pass which gives us the weight changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(y_hat, y, z_1, x):\n",
    "    val1 = loss_deri(y_hat[0], y[0]) * sigmoid_deri(x)\n",
    "    val2 = loss_deri(y_hat[1], y[1]) * sigmoid_deri(x)\n",
    "\n",
    "    return np.array([val1*x, val1, val2*x, val2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update_weights function then updates the weights accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(w, dw):\n",
    "    w = w-n*dw # Pointwise actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "First, wegenerate some data that should be classified. In this case, we draw examples from two Gaussians, one with mean 0 and one with mean 10. Group A has the label \"1\", and group B the label \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_points = 2000\n",
    "data_g1 = np.transpose(np.array([np.random.randn(num_data_points), -1*np.ones(num_data_points)]))\n",
    "data_g2 = np.transpose(np.array([np.random.randn(num_data_points)+10, np.ones(num_data_points)]))\n",
    "\n",
    "data = np.concatenate((data_g1, data_g2))\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now split the data set into a training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = int(num_data_points*2*0.75)\n",
    "data_train = data[:ind][:]\n",
    "data_eval = data[ind:][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start our training epoch. We use the classical \"Batch Gradient Descent\" which sweeps through the data, and averages the weight changes for each data point before updating the weight.\n",
    "Once the sweep is over, the weights are updated accordingly, and the next epoch is started. The 200 epochs is chosen randomly, we just want to make sure that the best possible value is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    dw = 0\n",
    "    for data_point in data_train:\n",
    "        z_1, y_hat, loss_val, y = forward_pass(data_point[0], data_point[1])\n",
    "        dw += backward_pass(y_hat, y, z_1, data_point[0])\n",
    "    dw /= len(data_train)\n",
    "    update_weights(w, dw)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate the accuracy of the algorithm. We devide the number of correct assignments by all assignments to get a percentage of how well the algorithm was able to devide the two grou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.724\n"
     ]
    }
   ],
   "source": [
    "correctly_pre = 0\n",
    "for data_point in data_eval:\n",
    "    if sigmoid(w[0]*data_point[0]+w[1]) < sigmoid(w[2]*data_point[0]+w[2]):\n",
    "        y_pred = 1\n",
    "    else:\n",
    "        y_pred = -1\n",
    "    if(y_pred == data_point[1]):\n",
    "        correctly_pre+=1\n",
    "        \n",
    "acc = correctly_pre / len(data_eval)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
